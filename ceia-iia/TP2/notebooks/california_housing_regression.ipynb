{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Trabajo Práctico N°2 - Introducción a Inteligencia Artificial | Regresión del valor de valor medio de casas en distritos de California\n",
    "\n",
    "Este es un [dataset](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset) muy popular que vamos a leer desde **Scikit-Learn**.\n",
    "\n",
    "Se requiere construir un modelo de regresión que nos permita predecir el valor medio de las casas en distintos distritos de California (medido en cientos de miles de dólares, es decir, $100,000). Este conjunto de datos proviene del censo de EE. UU. de 1990, donde cada observación corresponde a un bloque. Un bloque es la unidad geográfica más pequeña para la cual la Oficina del Censo de EE. UU. publica datos de muestra (típicamente con una población de entre 600 y 3,000 personas).\n",
    "\n",
    "\n",
    "Un hogar es un grupo de personas que residen dentro de una misma vivienda. Dado que el número promedio de habitaciones y dormitorios en este conjunto de datos se proporciona por hogar, estas columnas pueden tomar valores altos en bloques con pocos hogares y muchas viviendas vacías.\n",
    "\n",
    "Los atributos, en el orden en que se guardaron en el dataset, son:\n",
    "\n",
    "- `MedInc`: Ingreso medio del bloque\n",
    "- `HouseAge`: Edad mediana de las viviendas en el bloque\n",
    "- `AveRooms`: Número promedio de habitaciones por hogar\n",
    "- `AveBedrms`: Número promedio de dormitorios por hogar\n",
    "- `Population`: Población del bloque\n",
    "- `AveOccup`: Número promedio de personas por hogar\n",
    "- `Latitude`: Latitud del bloque\n",
    "- `Longitude`: Longitud del bloque"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### Import de librerías y datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Lectura del dataset\n",
    "california_housing = fetch_california_housing()\n",
    "\n",
    "# Obtenemos los atributos y el target:\n",
    "X = california_housing.data\n",
    "y = california_housing.target\n",
    "\n",
    "# Transformamos los datos a estructuras de Pandas:\n",
    "X = pd.DataFrame(X, columns=california_housing['feature_names'])\n",
    "y = pd.Series(y, name=california_housing['target_names'][0])\n",
    "\n",
    "# Unimos X e y; esto es útil para generar el mapa de calor de correlaciones\n",
    "df_california = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Análisis exploratorio de datos (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_california.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7fb6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_california.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_california.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"talk\")\n",
    "sns.set_style(\"ticks\")\n",
    "sns.heatmap(df_california.corr(), annot=True, cmap='coolwarm', annot_kws={\"size\": 10}, fmt=\".2f\", cbar=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = \"MedHouseVal\"\n",
    "\n",
    "corr = df_california.corr()[[feature]].sort_values(by=feature, ascending=False)\n",
    "\n",
    "plt.figure(figsize=(4, 8))\n",
    "sns.heatmap(corr, annot=True, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "plt.title(f\"Correlación de {feature} con otras variables\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Las features mas corelacionadas con el target son: MedInc; AveRooms; y Latitude. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairplot para correlación entre variables y target\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.pairplot(data=df_california, diag_kind='kde', corner=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafico de histograma de features numéricas\n",
    "num_cols = df_california.select_dtypes(include='number').columns\n",
    "n_cols = 3  # cantidad de columnas en la grilla\n",
    "n_rows = (len(num_cols) + n_cols - 1) // n_cols  # filas necesarias\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(5 * n_cols, 4 * n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(num_cols):\n",
    "    sns.histplot(df_california[col], bins=30, ax=axes[i], kde=False)\n",
    "    axes[i].set_title(f'Histograma de {col}')\n",
    "\n",
    "# Sacar ejes vacíos si hay\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### División en entrenamiento y evaluación; normalización "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,  y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# realizamos un heatmap sobre la matriz X resultante, population esta fuera de escala. \n",
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"talk\")\n",
    "sns.set_style(\"ticks\")\n",
    "sns.heatmap(X_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalado de los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=california_housing['feature_names'])\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=california_housing['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# realizamos un heatmap sobre la matriz X resultante, datos mas escalados ahora\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"talk\")\n",
    "sns.set_style(\"ticks\")\n",
    "sns.heatmap(X_train_scaled)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Modelos: Regresión Lineal y Ridge (con búsqueda de hiperparametro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seteamos modelo inicial de regresión \n",
    "\n",
    "Linear = LinearRegression()\n",
    "Linear.fit(X_train_scaled, y_train)\n",
    "\n",
    "scoring = ['r2', 'neg_mean_squared_error', 'neg_mean_absolute_error']\n",
    "\n",
    "scores = cross_validate(Linear, X_train_scaled, y_train, cv=5, scoring=scoring, return_train_score=False)\n",
    "\n",
    "print(\"R2 scores:\", scores['test_r2'])\n",
    "print(\"MSE scores:\", -scores['test_neg_mean_squared_error'])\n",
    "print(\"MAE scores:\", -scores['test_neg_mean_absolute_error'])\n",
    "\n",
    "print(\"\\nPromedios:\")\n",
    "print(\"R2 promedio:\", np.mean(scores['test_r2']))\n",
    "print(\"MSE promedio:\", -np.mean(scores['test_neg_mean_squared_error']))\n",
    "print(\"MAE promedio:\", -np.mean(scores['test_neg_mean_absolute_error']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados para ejercicio n°3 \n",
    "\n",
    "y_pred_train = Linear.predict(X_train_scaled)\n",
    "\n",
    "TSS = ((y_train - y_train.mean())**2).sum() #TSS total sum of squares\n",
    "RSS = ((y_train - y_pred_train)**2).sum() #RSS residual sum of squares\n",
    "ESS = ((y_pred_train - y_train.mean())**2).sum() # ESS explained sum of squares\n",
    "\n",
    "r2_linear = ESS / TSS  # o 1 - RSS / TSS\n",
    "\n",
    "print(\"\\nComparación de varianza:\")\n",
    "print(f\"Varianza total de los datos (TSS): {TSS}\")\n",
    "print(f\"Varianza residual (RSS): {RSS}\")\n",
    "print(f\"Varianza explicada por el modelo (ESS): {ESS}\")\n",
    "print(f\"Coeficiente de determinación (R^2): {r2_linear:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rango de alpha\n",
    "alpha_range = np.linspace(0.01, 12.5, 50)  # 50 valores entre 0.01 y 12.5\n",
    "\n",
    "# Modelo Ridge\n",
    "ridge = Ridge()\n",
    "\n",
    "# Definir scoring (MSE negativo porque sklearn maximiza la métrica)\n",
    "scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "# GridSearch con CV de 5 folds\n",
    "param_grid = {'alpha': alpha_range}\n",
    "grid = GridSearchCV(ridge, param_grid, cv=5, scoring=scorer)\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Extraer resultados\n",
    "mean_scores_ridge = -grid.cv_results_['mean_test_score']  # convertir a positivo\n",
    "best_alpha = grid.best_params_['alpha']\n",
    "\n",
    "print(f\"Mejor alpha: {best_alpha}\")\n",
    "print(f\"MSE promedio con mejor alpha: {mean_scores_ridge[grid.best_index_]}\")\n",
    "\n",
    "best_ridge = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar MSE vs alpha\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(alpha_range, mean_scores_ridge, marker='o')\n",
    "plt.xlabel(\"Alpha\")\n",
    "plt.ylabel(\"MSE (validación cruzada)\")\n",
    "plt.title(\"Ridge Regression: MSE vs Alpha (5-fold CV)\")\n",
    "plt.axvline(best_alpha, color='r', linestyle='--', label=f'Mejor alpha = {best_alpha:.2f}')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### Resultados y conclusiones TP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "#### Ejecución de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validacion de resultados contra validation set \n",
    "\n",
    "# Baseline\n",
    "\n",
    "baseline = y_train.mean()\n",
    "y_pred_baseline = np.full(len(y_test), baseline)\n",
    "\n",
    "r2_score_baseline = r2_score(y_test, y_pred_baseline)\n",
    "mae_baseline = mean_absolute_error(y_test, y_pred_baseline)\n",
    "mse_baseline = mean_squared_error(y_test, y_pred_baseline)\n",
    "\n",
    "print(\"\\nResultados para Baseline (media):\")\n",
    "print(\"R²:\", r2_score_baseline)\n",
    "print(\"MSE:\", mse_baseline)\n",
    "print(\"MAE:\", mae_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validacion de resultados contra validation set \n",
    "\n",
    "# Linear\n",
    "\n",
    "y_pred_linear = Linear.predict(X_test_scaled)\n",
    "\n",
    "r2_score_linear = r2_score(y_test, y_pred_linear)\n",
    "mae_linear = mean_absolute_error(y_test, y_pred_linear)\n",
    "mse_linear = mean_squared_error(y_test, y_pred_linear)\n",
    "\n",
    "variance_linear = np.var(y_test - y_pred_linear)\n",
    "\n",
    "print(\"\\nResultados para regresión lineal:\")\n",
    "print(\"R²:\", r2_score_linear)\n",
    "print(\"MSE:\", mse_linear)\n",
    "print(\"MAE:\", mae_linear)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validacion de resultados contra validation set \n",
    "\n",
    "# Ridge\n",
    "\n",
    "y_pred_ridge = best_ridge.predict(X_test_scaled)\n",
    "\n",
    "r2_score_ridge = r2_score(y_test, y_pred_ridge)\n",
    "mae_ridge = mean_absolute_error(y_test, y_pred_ridge)\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "\n",
    "print(\"\\nResultados para regresión Ridge:\")\n",
    "print(\"R²:\", r2_score_ridge)\n",
    "print(\"MSE:\", mse_ridge)\n",
    "print(\"MAE:\", mae_ridge)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "#### Resultados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio n°3: comparación de resultados de varianza de modelo vs datos. \n",
    "print(\"\\nComparación de varianza\")\n",
    "print(\"Varianza de los datos:\", np.var(y_test))\n",
    "print(\"Varianza del modelo lineal:\", variance_linear)\n",
    "print(\"Coeficiente de Pearson (R2) para la regresión lineal:\", r2_score_linear)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Formulación de tabla comparativa de resultados\n",
    "\n",
    "results = {\n",
    "    'Model': ['Baseline', 'Linear Regression', f'Ridge (α={best_alpha:.2f})'],\n",
    "    'R²': [\n",
    "        r2_score_baseline,\n",
    "        r2_score_linear,\n",
    "        r2_score_ridge\n",
    "    ],\n",
    "    'MSE': [\n",
    "        mse_baseline,\n",
    "        mse_linear,\n",
    "        mse_ridge\n",
    "    ],\n",
    "    'MAE': [\n",
    "        mae_baseline,\n",
    "        mae_linear,\n",
    "        mae_ridge\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Crear DataFrame\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Mostrar tabla con formato\n",
    "styled = (\n",
    "    df_results.style\n",
    "    .format({'R²': '{:.4f}', 'MSE': '{:.4f}', 'MAE': '{:.4f}'})\n",
    "    .set_properties(**{'text-align': 'center'})\n",
    ")\n",
    "\n",
    "styled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados son bastante mediocres, se podría intentar retirar outliers de MedHouseVal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "### Propuesta de mejora de modelo \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datos de medhouseval \n",
    "df_california['MedHouseVal'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_california[\"MedHouseVal\"].plot(kind=\"box\")\n",
    "plt.title(\"Boxplot de MedHouseVal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de outliers \n",
    "col = df_california[\"MedHouseVal\"]\n",
    "Q1 = col.quantile(0.25)\n",
    "Q3 = col.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "#limites\n",
    "limite_superior = Q3 + 1.5 * IQR\n",
    "limite_inferior = Q1 - 1.5 * IQR\n",
    "\n",
    "df_california_filtrada = df_california[(col >= limite_inferior) & (col <= limite_superior)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cantidad con outliers:\", len(df_california))\n",
    "print(\"Cantidad sin outliers:\", len(df_california_filtrada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = df_california_filtrada.drop(columns=['MedHouseVal'])\n",
    "y_new = df_california_filtrada['MedHouseVal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_new,  y_new, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalado de los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=california_housing['feature_names'])\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=california_housing['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seteamos modelo inicial de regresión \n",
    "\n",
    "Linear = LinearRegression()\n",
    "Linear.fit(X_train_scaled, y_train)\n",
    "\n",
    "scoring = ['r2', 'neg_mean_squared_error', 'neg_mean_absolute_error']\n",
    "\n",
    "scores = cross_validate(Linear, X_train_scaled, y_train, cv=5, scoring=scoring, return_train_score=False)\n",
    "\n",
    "print(\"R2 scores:\", scores['test_r2'])\n",
    "print(\"MSE scores:\", -scores['test_neg_mean_squared_error'])\n",
    "print(\"MAE scores:\", -scores['test_neg_mean_absolute_error'])\n",
    "\n",
    "print(\"\\nPromedios:\")\n",
    "print(\"R2 promedio:\", np.mean(scores['test_r2']))\n",
    "print(\"MSE promedio:\", -np.mean(scores['test_neg_mean_squared_error']))\n",
    "print(\"MAE promedio:\", -np.mean(scores['test_neg_mean_absolute_error']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rango de alpha\n",
    "alpha_range = np.linspace(0.01, 12.5, 50)  # 50 valores entre 0.01 y 12.5\n",
    "\n",
    "# Modelo Ridge\n",
    "ridge = Ridge()\n",
    "\n",
    "# Definir scoring (MSE negativo porque sklearn maximiza la métrica)\n",
    "scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "# GridSearch con CV de 5 folds\n",
    "param_grid = {'alpha': alpha_range}\n",
    "grid = GridSearchCV(ridge, param_grid, cv=5, scoring=scorer)\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Extraer resultados\n",
    "mean_scores_ridge = -grid.cv_results_['mean_test_score']  # convertir a positivo\n",
    "best_alpha_2 = grid.best_params_['alpha']\n",
    "\n",
    "print(f\"Mejor alpha: {best_alpha_2}\")\n",
    "print(f\"MSE promedio con mejor alpha: {mean_scores_ridge[grid.best_index_]}\")\n",
    "\n",
    "best_ridge = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validacion de resultados contra validation set \n",
    "\n",
    "# Linear\n",
    "\n",
    "y_pred_linear = Linear.predict(X_test_scaled)\n",
    "\n",
    "r2_score_linear_2 = r2_score(y_test, y_pred_linear)\n",
    "mae_linear_2 = mean_absolute_error(y_test, y_pred_linear)\n",
    "mse_linear_2 = mean_squared_error(y_test, y_pred_linear)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validacion de resultados contra validation set \n",
    "\n",
    "# Ridge\n",
    "\n",
    "y_pred_ridge = best_ridge.predict(X_test_scaled)\n",
    "\n",
    "r2_score_ridge_2 = r2_score(y_test, y_pred_ridge)\n",
    "mae_ridge_2 = mean_absolute_error(y_test, y_pred_ridge)\n",
    "mse_ridge_2 = mean_squared_error(y_test, y_pred_ridge)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Formulación de tabla comparativa de resultados\n",
    "\n",
    "results = {\n",
    "    'Model': ['Baseline', 'Linear Regression', f'Ridge (α={best_alpha:.2f})', 'Linear Regression (Outliers Removed)', f'Ridge (Outliers removed, α={best_alpha_2:.2f})'],\n",
    "    'R²': [\n",
    "        r2_score_baseline,\n",
    "        r2_score_linear,\n",
    "        r2_score_ridge,\n",
    "        r2_score_linear_2,\n",
    "        r2_score_ridge_2\n",
    "    ],\n",
    "    'MSE': [\n",
    "        mse_baseline,\n",
    "        mse_linear,\n",
    "        mse_ridge,\n",
    "        mse_linear_2,\n",
    "        mse_ridge_2\n",
    "    ],\n",
    "    'MAE': [\n",
    "        mae_baseline,\n",
    "        mae_linear,\n",
    "        mae_ridge,\n",
    "        mae_linear_2,\n",
    "        mae_ridge_2\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Crear DataFrame\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Mostrar tabla con formato\n",
    "styled = (\n",
    "    df_results.style\n",
    "    .format({'R²': '{:.4f}', 'MSE': '{:.4f}', 'MAE': '{:.4f}'})\n",
    "    .set_properties(**{'text-align': 'center'})\n",
    ")\n",
    "\n",
    "styled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo mejora 0.06 en R2 y reduce MSE en alrededor de 0.2, asi como 0.06 en MAE. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TP2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
